{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd91bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load human text (from persuade_combined.csv)\n",
    "persuade_path = '/kaggle/input/persuade-corpus-ai-generated-dataset/persuade_combined.csv'\n",
    "persuade_df = pd.read_csv(persuade_path)\n",
    "\n",
    "# Keep only human-written texts (generated == 0)\n",
    "human_df = persuade_df[persuade_df['generated'] == 0].copy()\n",
    "human_df = human_df[['text']]  # Keep only text column\n",
    "human_df['generated'] = 0      # Add label column\n",
    "\n",
    "print(f\"Number of human texts: {len(human_df)}\")\n",
    "\n",
    "# 2. Load generated text (from slimpajama.csv)\n",
    "slimpajama_path = '/kaggle/input/slimpajama-ai-generated-parallel-dataset/slimpajama.csv'\n",
    "slimpajama_df = pd.read_csv(slimpajama_path)\n",
    "\n",
    "# Ensure we only use 'text' column, randomly sample AI texts at 10x the human text count\n",
    "ai_df = slimpajama_df[['text']].sample(n=10 * len(human_df), random_state=42).copy()\n",
    "ai_df['generated'] = 1  # Add label column\n",
    "\n",
    "print(f\"Number of AI-generated texts: {len(ai_df)}\")\n",
    "\n",
    "# 3. Combine datasets and shuffle\n",
    "combined_df = pd.concat([human_df, ai_df], ignore_index=True)\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 4. Save the new training set\n",
    "output_path = '/kaggle/working/combined_training_data_large.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nâœ… New training data saved to: {output_path}\")\n",
    "print(f\"Total samples: {len(combined_df)} (Human: {len(human_df)}, AI: {len(ai_df)})\")\n",
    "# Explicitly disable wandb\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    # np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "set_seed()\n",
    "\n",
    "# Check GPU availability and print info\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"GPU memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n",
    "\n",
    "# 1. Load data\n",
    "train_df = combined_df\n",
    "test_df = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n",
    "\n",
    "# Clean data - keep id column\n",
    "train_df = train_df[['text', 'generated']].dropna()\n",
    "test_df = test_df[['id', 'text']].dropna()\n",
    "\n",
    "# 2. Split train/validation sets\n",
    "train_split, val_split = train_test_split(train_df, test_size=0.1, random_state=42, stratify=train_df['generated'])\n",
    "\n",
    "# 3. Convert to HuggingFace datasets\n",
    "train_dataset = Dataset.from_pandas(train_split)\n",
    "val_dataset = Dataset.from_pandas(val_split)\n",
    "\n",
    "# 4. Use DeBERTa model\n",
    "model_name = \"microsoft/deberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Ensure model runs on GPU (if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 5. Tokenize function - limit length for stability\n",
    "def tokenize_fn(example):\n",
    "    return tokenizer(example['text'], truncation=True, padding='max_length', max_length=384)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "# 6. Set label field name\n",
    "if \"generated\" in train_dataset.column_names:\n",
    "    train_dataset = train_dataset.rename_column(\"generated\", \"labels\")\n",
    "if \"generated\" in val_dataset.column_names:\n",
    "    val_dataset = val_dataset.rename_column(\"generated\", \"labels\")\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# 7. Training arguments - use stable settings\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,  # Lower learning rate\n",
    "    per_device_train_batch_size=8,  # Smaller batch size\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    save_total_limit=1,\n",
    "    fp16=False,\n",
    "    bf16=False,  # Explicitly disable bf16\n",
    "    report_to=\"none\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    logging_strategy=\"steps\",\n",
    "    gradient_accumulation_steps=4,  # Increase gradient accumulation steps\n",
    "    dataloader_num_workers=0,  # Reduce parallel loading\n",
    "    warmup_ratio=0.1,  # Add warmup steps\n",
    "    max_grad_norm=1.0,  # Limit gradient norm\n",
    ")\n",
    "\n",
    "# 8. Evaluation function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)  # Use numpy instead of torch\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds),\n",
    "    }\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "import time\n",
    "import math\n",
    "\n",
    "class ProgressCallback(TrainerCallback):\n",
    "    def __init__(self, print_freq=10):\n",
    "        self.print_freq = print_freq\n",
    "        self.start_time = time.time()\n",
    "        self.step_start_time = self.start_time\n",
    "        self.last_log_step = 0\n",
    "    \n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        print(f\"Starting training, total {args.num_train_epochs} epochs\")\n",
    "        \n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        self.epoch_start_time = time.time()\n",
    "        print(f\"\\nStarting epoch {state.epoch+1}/{args.num_train_epochs}\")\n",
    "        \n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step > 0 and (state.global_step % self.print_freq == 0 or state.global_step == 1):\n",
    "            # Calculate current epoch progress\n",
    "            steps_per_epoch = state.max_steps // args.num_train_epochs\n",
    "            current_epoch_step = state.global_step % steps_per_epoch if steps_per_epoch > 0 else state.global_step\n",
    "            if steps_per_epoch > 0:\n",
    "                epoch_progress = (current_epoch_step / steps_per_epoch) * 100\n",
    "            else:\n",
    "                epoch_progress = 0\n",
    "                \n",
    "            # Calculate speed\n",
    "            current_time = time.time()\n",
    "            steps_since_last_log = state.global_step - self.last_log_step\n",
    "            time_since_last_log = current_time - self.step_start_time\n",
    "            if time_since_last_log > 0:\n",
    "                steps_per_second = steps_since_last_log / time_since_last_log\n",
    "            else:\n",
    "                steps_per_second = 0\n",
    "                \n",
    "            # Calculate remaining time\n",
    "            if steps_per_second > 0:\n",
    "                steps_remaining = state.max_steps - state.global_step\n",
    "                est_time_remaining = steps_remaining / steps_per_second\n",
    "                mins_remaining = est_time_remaining // 60\n",
    "                secs_remaining = est_time_remaining % 60\n",
    "                time_remaining = f\"{int(mins_remaining)}min{int(secs_remaining)}sec\"\n",
    "            else:\n",
    "                time_remaining = \"calculating...\"\n",
    "                \n",
    "            print(f\"Epoch {state.epoch+1}/{args.num_train_epochs} | \"\n",
    "                  f\"Step {current_epoch_step}/{steps_per_epoch} | \"\n",
    "                  f\"Progress {epoch_progress:.2f}% | \"\n",
    "                  f\"Total progress {(state.global_step/state.max_steps)*100:.2f}% | \"\n",
    "                  f\"Speed {steps_per_second:.2f} steps/sec | \"\n",
    "                  f\"Est. time remaining {time_remaining}\")\n",
    "            \n",
    "            self.last_log_step = state.global_step\n",
    "            self.step_start_time = current_time\n",
    "            \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        print(f\"Epoch {state.epoch+1} completed, time: {epoch_time:.2f}sec\")\n",
    "        \n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        total_time = time.time() - self.start_time\n",
    "        hours = total_time // 3600\n",
    "        mins = (total_time % 3600) // 60\n",
    "        secs = total_time % 60\n",
    "        print(f\"\\nTraining complete! Total time: {int(hours)}h{int(mins)}m{int(secs)}s\")\n",
    "\n",
    "# Modified Trainer initialization\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[ProgressCallback(print_freq=20)],\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save trained model\n",
    "model_save_path = \"/kaggle/working/deberta_model_persuade_V2\"\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Evaluate model on validation set\n",
    "print(\"\\nEvaluating model on validation set:\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Validation accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Validation F1 score: {eval_results['eval_f1']:.4f}\")\n",
    "\n",
    "# Process test set\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "\n",
    "# Model predictions\n",
    "print(\"Generating predictions...\")\n",
    "test_outputs = trainer.predict(test_dataset)\n",
    "test_preds = np.argmax(test_outputs.predictions, axis=-1)  # Use numpy instead of torch\n",
    "\n",
    "# Output detailed results\n",
    "detailed_df = test_df.copy()\n",
    "detailed_df['generated_pred'] = test_preds\n",
    "detailed_df.to_csv(\"/kaggle/working/deberta_detailed_predictions.csv\", index=False)\n",
    "print(\"Detailed prediction results saved\")\n",
    "\n",
    "probs = torch.nn.functional.softmax(torch.tensor(test_outputs.predictions), dim=-1).numpy()\n",
    "predicted_probs = probs[:, 1]  # Probability of AI-generated (label=1)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'generated': predicted_probs\n",
    "})\n",
    "submission_df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "\n",
    "# Print statistics\n",
    "# print(f\"Number of predicted AI-generated texts: {sum(test_preds)}\")\n",
    "# print(f\"Number of predicted human-written texts: {len(test_preds) - sum(test_preds)}\")\n",
    "# print(f\"Percentage of predicted AI-generated texts: {sum(test_preds) / len(test_preds) * 100:.2f}%\")\n",
    "model_path = \"/kaggle/input/deberta_final/pytorch/default/1/deberta_model_persuade_V2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "print(\"Model class count:\", config.num_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan6600",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
